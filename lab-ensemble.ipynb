{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values - filling numerical columns with median and categorical with mode\n",
    "spaceship['Age'].fillna(spaceship['Age'].median(), inplace=True)\n",
    "spaceship['RoomService'].fillna(spaceship['RoomService'].median(), inplace=True)\n",
    "spaceship['FoodCourt'].fillna(spaceship['FoodCourt'].median(), inplace=True)\n",
    "spaceship['ShoppingMall'].fillna(spaceship['ShoppingMall'].median(), inplace=True)\n",
    "spaceship['Spa'].fillna(spaceship['Spa'].median(), inplace=True)\n",
    "spaceship['VRDeck'].fillna(spaceship['VRDeck'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship['HomePlanet'].fillna(spaceship['HomePlanet'].mode()[0], inplace=True)\n",
    "spaceship['CryoSleep'].fillna(spaceship['CryoSleep'].mode()[0], inplace=True)\n",
    "spaceship['Cabin'].fillna(spaceship['Cabin'].mode()[0], inplace=True)\n",
    "spaceship['Destination'].fillna(spaceship['Destination'].mode()[0], inplace=True)\n",
    "spaceship['VIP'].fillna(spaceship['VIP'].mode()[0], inplace=True)\n",
    "spaceship['Name'].fillna(spaceship['Name'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical columns to category type\n",
    "categorical_columns = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']\n",
    "for col in categorical_columns:\n",
    "    spaceship[col] = spaceship[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship['Transported'] = spaceship['Transported'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spaceship.drop(columns=['Transported', 'PassengerId', 'Name'])\n",
    "y = spaceship['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
      "       'CryoSleep_True', 'Cabin_E/397/P', 'Cabin_F/1417/P', 'Cabin_F/682/S',\n",
      "       'Cabin_G/880/S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (after feature selection): (6954, 10)\n",
      "Testing set shape (after feature selection): (1739, 10)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the train and test sets after feature selection\n",
    "print(f\"Training set shape (after feature selection): {X_train_selected.shape}\")\n",
    "print(f\"Testing set shape (after feature selection): {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RoomService  FoodCourt  ShoppingMall       Spa    VRDeck  CryoSleep_True  \\\n",
      "0    -0.326853  -0.251604     -0.282179  0.312621 -0.256843       -0.725954   \n",
      "1    -0.326853   0.479133     -0.231124 -0.279427 -0.256843       -0.725954   \n",
      "2    -0.326853  -0.286859     -0.282179 -0.279427 -0.256843        1.377498   \n",
      "3    -0.326853  -0.285577      0.193788  0.601424 -0.256843       -0.725954   \n",
      "4    -0.326853  -0.286859     -0.282179 -0.279427 -0.256843        1.377498   \n",
      "\n",
      "   Cabin_E/397/P  Cabin_F/1417/P  Cabin_F/682/S  Cabin_G/880/S  \n",
      "0      -0.011993       -0.011993      -0.011993      -0.011993  \n",
      "1      -0.011993       -0.011993      -0.011993      -0.011993  \n",
      "2      -0.011993       -0.011993      -0.011993      -0.011993  \n",
      "3      -0.011993       -0.011993      -0.011993      -0.011993  \n",
      "4      -0.011993       -0.011993      -0.011993      -0.011993  \n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows of the scaled and selected training set\n",
    "print(pd.DataFrame(X_train_selected, columns=selected_features).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Bagging with Decision Tree Classifier\n",
    "bagging_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100,\n",
    "    max_samples=0.8, bootstrap=True, random_state=42\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X_train_selected, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7740\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Bagging Accuracy: {accuracy_bagging:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting Accuracy: 0.7723\n"
     ]
    }
   ],
   "source": [
    "# Pasting with Decision Tree Classifier\n",
    "pasting_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100,\n",
    "    max_samples=0.8, bootstrap=False, random_state=42\n",
    ")\n",
    "\n",
    "pasting_clf.fit(X_train_selected, y_train)\n",
    "y_pred_pasting = pasting_clf.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_pasting = accuracy_score(y_test, y_pred_pasting)\n",
    "print(f\"Pasting Accuracy: {accuracy_pasting:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7780\n",
      "Confusion Matrix:\n",
      " [[623 238]\n",
      " [148 730]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76       861\n",
      "           1       0.75      0.83      0.79       878\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.78      0.78      0.78      1739\n",
      "weighted avg       0.78      0.78      0.78      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Random Forest with Decision Tree Classifier\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_clf.fit(X_train_selected, y_train)\n",
    "y_pred_rf = random_forest_clf.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred_rf)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7780\n",
      "Confusion Matrix:\n",
      " [[603 258]\n",
      " [128 750]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76       861\n",
      "           1       0.74      0.85      0.80       878\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.78      0.78      0.78      1739\n",
      "weighted avg       0.78      0.78      0.78      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_clf.fit(X_train_selected, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_gb:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_gb)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred_gb)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m X_test_selected \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mtransform(X_test_scaled)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# AdaBoost Classifier with Decision Tree Classifier as the base estimator\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m ada_clf \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(\n\u001b[0;32m      8\u001b[0m     base_estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      9\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     10\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m ada_clf\u001b[38;5;241m.\u001b[39mfit(X_train_selected, y_train)\n\u001b[0;32m     15\u001b[0m y_pred_ada \u001b[38;5;241m=\u001b[39m ada_clf\u001b[38;5;241m.\u001b[39mpredict(X_test_selected)\n",
      "\u001b[1;31mTypeError\u001b[0m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# AdaBoost Classifier with Decision Tree Classifier as the base estimator\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train_selected, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_ada:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_ada)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred_ada)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gianf\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.7786\n",
      "Confusion Matrix:\n",
      " [[601 260]\n",
      " [125 753]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       861\n",
      "           1       0.74      0.86      0.80       878\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.79      0.78      0.78      1739\n",
      "weighted avg       0.79      0.78      0.78      1739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gianf\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.7786\n",
      "Confusion Matrix:\n",
      " [[601 260]\n",
      " [125 753]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       861\n",
      "           1       0.74      0.86      0.80       878\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.79      0.78      0.78      1739\n",
      "weighted avg       0.79      0.78      0.78      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "\n",
    "# Handling missing values\n",
    "spaceship['Age'].fillna(spaceship['Age'].median(), inplace=True)\n",
    "spaceship['RoomService'].fillna(spaceship['RoomService'].median(), inplace=True)\n",
    "spaceship['FoodCourt'].fillna(spaceship['FoodCourt'].median(), inplace=True)\n",
    "spaceship['ShoppingMall'].fillna(spaceship['ShoppingMall'].median(), inplace=True)\n",
    "spaceship['Spa'].fillna(spaceship['Spa'].median(), inplace=True)\n",
    "spaceship['VRDeck'].fillna(spaceship['VRDeck'].median(), inplace=True)\n",
    "spaceship['HomePlanet'].fillna(spaceship['HomePlanet'].mode()[0], inplace=True)\n",
    "spaceship['CryoSleep'].fillna(spaceship['CryoSleep'].mode()[0], inplace=True)\n",
    "spaceship['Cabin'].fillna(spaceship['Cabin'].mode()[0], inplace=True)\n",
    "spaceship['Destination'].fillna(spaceship['Destination'].mode()[0], inplace=True)\n",
    "spaceship['VIP'].fillna(spaceship['VIP'].mode()[0], inplace=True)\n",
    "spaceship['Name'].fillna(spaceship['Name'].mode()[0], inplace=True)\n",
    "\n",
    "# Converting categorical columns to category type\n",
    "categorical_columns = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']\n",
    "for col in categorical_columns:\n",
    "    spaceship[col] = spaceship[col].astype('category')\n",
    "\n",
    "# Convert 'Transported' column to binary\n",
    "spaceship['Transported'] = spaceship['Transported'].astype('int')\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = spaceship.drop(columns=['Transported', 'PassengerId', 'Name'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = spaceship['Transported']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# AdaBoost Classifier with Decision Tree Classifier as the base estimator\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train_selected, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_ada:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_ada)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred_ada)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "\n",
    "# Handling missing values\n",
    "spaceship['Age'].fillna(spaceship['Age'].median(), inplace=True)\n",
    "spaceship['RoomService'].fillna(spaceship['RoomService'].median(), inplace=True)\n",
    "spaceship['FoodCourt'].fillna(spaceship['FoodCourt'].median(), inplace=True)\n",
    "spaceship['ShoppingMall'].fillna(spaceship['ShoppingMall'].median(), inplace=True)\n",
    "spaceship['Spa'].fillna(spaceship['Spa'].median(), inplace=True)\n",
    "spaceship['VRDeck'].fillna(spaceship['VRDeck'].median(), inplace=True)\n",
    "spaceship['HomePlanet'].fillna(spaceship['HomePlanet'].mode()[0], inplace=True)\n",
    "spaceship['CryoSleep'].fillna(spaceship['CryoSleep'].mode()[0], inplace=True)\n",
    "spaceship['Cabin'].fillna(spaceship['Cabin'].mode()[0], inplace=True)\n",
    "spaceship['Destination'].fillna(spaceship['Destination'].mode()[0], inplace=True)\n",
    "spaceship['VIP'].fillna(spaceship['VIP'].mode()[0], inplace=True)\n",
    "spaceship['Name'].fillna(spaceship['Name'].mode()[0], inplace=True)\n",
    "\n",
    "# Converting categorical columns to category type\n",
    "categorical_columns = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']\n",
    "for col in categorical_columns:\n",
    "    spaceship[col] = spaceship[col].astype('category')\n",
    "\n",
    "# Convert 'Transported' column to binary\n",
    "spaceship['Transported'] = spaceship['Transported'].astype('int')\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = spaceship.drop(columns=['Transported', 'PassengerId', 'Name'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = spaceship['Transported']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection using mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# AdaBoost Classifier with Decision Tree Classifier as the base estimator\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train_selected, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_ada:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_ada)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred_ada)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
