{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "spaceship.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "spaceship = spaceship.dropna()\n",
    "\n",
    "X = spaceship.drop(columns=['PassengerId', 'Name', 'Cabin', 'Transported'])\n",
    "y = spaceship['Transported']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "X_cat_trans = ohe.fit_transform(X[['HomePlanet', 'CryoSleep', 'Destination', 'VIP']])\n",
    "X_cat_trans_df = pd.DataFrame(X_cat_trans, columns=ohe.get_feature_names_out(), index=X.index)\n",
    "\n",
    "X = X.drop(columns=['HomePlanet', 'CryoSleep', 'Destination', 'VIP'])\n",
    "X = pd.concat([X, X_cat_trans_df], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regression\n",
      "MAE: 0.29\n",
      "RMSE: 0.41\n",
      "R2 score: 0.32\n",
      "Accuracy: 0.75\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# K-Nearest Neighbors Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "# Train the model\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_knn = knn_reg.predict(X_test)\n",
    "y_pred_knn_binary = (y_pred_knn >= 0.5)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "rmse_knn = mean_squared_error(y_test, y_pred_knn, squared=False)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn_binary)\n",
    "\n",
    "\n",
    "print(f\"K-Nearest Neighbors Regression\")\n",
    "print(f\"MAE: {mae_knn:.2f}\")\n",
    "print(f\"RMSE: {rmse_knn:.2f}\")\n",
    "print(f\"R2 score: {r2_knn:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_knn:.2f}\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with K-Nearest Neighbors Regression\n",
      "MAE: 0.29\n",
      "RMSE: 0.40\n",
      "R2 score: 0.35\n",
      "Accuracy: 0.77\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting with K-Nearest Neighbors Regression\n",
      "MAE: 0.29\n",
      "RMSE: 0.41\n",
      "R2 score: 0.32\n",
      "Accuracy: 0.75\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "# Train the model\n",
    "bagging_knn = BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=50, random_state=0)\n",
    "bagging_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_bag_knn = bagging_knn.predict(X_test)\n",
    "y_pred_bag_knn_binary = (y_pred_bag_knn >= 0.5)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_bag_knn = mean_absolute_error(y_test, y_pred_bag_knn)\n",
    "rmse_bag_knn = mean_squared_error(y_test, y_pred_bag_knn, squared=False)\n",
    "r2_bag_knn = r2_score(y_test, y_pred_bag_knn)\n",
    "accuracy_bag_knn = accuracy_score(y_test, y_pred_bag_knn_binary)\n",
    "\n",
    "\n",
    "print(f\"Bagging with K-Nearest Neighbors Regression\")\n",
    "print(f\"MAE: {mae_bag_knn:.2f}\")\n",
    "print(f\"RMSE: {rmse_bag_knn:.2f}\")\n",
    "print(f\"R2 score: {r2_bag_knn:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_bag_knn:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# KKn\n",
    "pasting_knn = BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=50, bootstrap=False, random_state=0)\n",
    "pasting_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_paste_knn = pasting_knn.predict(X_test)\n",
    "y_pred_paste_knn_binary = (y_pred_paste_knn >= 0.5)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_paste_knn = mean_absolute_error(y_test, y_pred_paste_knn)\n",
    "rmse_paste_knn = mean_squared_error(y_test, y_pred_paste_knn, squared=False)\n",
    "r2_paste_knn = r2_score(y_test, y_pred_paste_knn)\n",
    "accuracy_paste_knn = accuracy_score(y_test, y_pred_paste_knn_binary)\n",
    "\n",
    "print(f\"Pasting with K-Nearest Neighbors Regression\")\n",
    "print(f\"MAE: {mae_paste_knn:.2f}\")\n",
    "print(f\"RMSE: {rmse_paste_knn:.2f}\")\n",
    "print(f\"R2 score: {r2_paste_knn:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_paste_knn:.2f}\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "MAE: 0.28\n",
      "RMSE: 0.39\n",
      "R2 score: 0.39\n",
      "Accuracy: 0.79\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train the model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_rf_binary = (y_pred_rf >= 0.5)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf_binary)\n",
    "\n",
    "\n",
    "print(f\"Random Forest Regressor\")\n",
    "print(f\"MAE: {mae_rf:.2f}\")\n",
    "print(f\"RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"R2 score: {r2_rf:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor\n",
      "MAE: 0.29\n",
      "RMSE: 0.38\n",
      "R2 score: 0.42\n",
      "Accuracy: 0.78\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train the model\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=100, random_state=0)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gb = gradient_boosting.predict(X_test)\n",
    "y_pred_gb_binary = (y_pred_gb >= 0.5)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "rmse_gb = mean_squared_error(y_test, y_pred_gb, squared=False)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb_binary)\n",
    "\n",
    "\n",
    "print(f\"Gradient Boosting Regressor\")\n",
    "print(f\"MAE: {mae_gb:.2f}\")\n",
    "print(f\"RMSE: {rmse_gb:.2f}\")\n",
    "print(f\"R2 score: {r2_gb:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_gb:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Regressor\n",
      "MAE: 0.36\n",
      "RMSE: 0.40\n",
      "R2 score: 0.35\n",
      "Accuracy: 0.78\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adaptive Boosting Regressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Train the model\n",
    "adaptive_boosting = AdaBoostRegressor(n_estimators=100, random_state=0)\n",
    "adaptive_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ab = adaptive_boosting.predict(X_test)\n",
    "y_pred_ab_binary = (y_pred_ab >= 0.5)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_ab = mean_absolute_error(y_test, y_pred_ab)\n",
    "rmse_ab = mean_squared_error(y_test, y_pred_ab, squared=False)\n",
    "r2_ab = r2_score(y_test, y_pred_ab)\n",
    "accuracy_ab = accuracy_score(y_test, y_pred_ab_binary)\n",
    "\n",
    "\n",
    "print(f\"Adaptive Boosting Regressor\")\n",
    "print(f\"MAE: {mae_ab:.2f}\")\n",
    "print(f\"RMSE: {rmse_ab:.2f}\")\n",
    "print(f\"R2 score: {r2_ab:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_ab:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor and Gradient Boosting Regressor are the top performers, with the Random Forest Regressor having a slight edge due to its slightly better MAE, RMSE, and Accuracy.\n",
    "#The Random Forest Regressor is the best model in this case, primarily due to its better overall balance of low MAE, competitive RMSE, good R2 score, and highest accuracy. This suggests it has the best predictive performance and classification accuracy among the models tested. However, the Gradient Boosting Regressor also performs very well and could be considered a close second, especially given its highest R2 score, indicating it might fit the data slightly better in some contexts.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
